# [Data augmentation](https://www.alexirpan.com/2020/05/07/rl-potpourri.html)
tags:
- [[reinforcement-learning]]

> The new hotness in RL is data augmentation. Three papers came out on arXiv in the past week: [Constrastive Unsupervised Reinforcement Learning (CURL)](https://arxiv.org/abs/2004.04136), from Srinivas and Laskin et al, [Image Augmentation is All You Need (DrQ)](https://arxiv.org/abs/2004.13649) from Kostrikov and Yarats et al, and [Reinforcement Learning with Augmented Data (RAD)](https://arxiv.org/abs/2004.14990) from Laskin and Lee et al. It also made it to VentureBeat of all places.

> data augmentation is just seems like the obvious thing to do. You can either view it as multiplying the size of your dataset by a constant factor, or you can view it as decreasing the probability your model learns a spurious correlation, but in either case it usually doesnâ€™t hurt and it often really helps.

[//begin]: # "Autogenerated link references for markdown compatibility"
[reinforcement-learning]: ..\reinforcement-learning "Reinforcement Learning"
[//end]: # "Autogenerated link references"