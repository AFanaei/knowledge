# [deep learning from foundation]
tags:
- [[deep-learning]]

### lesson 8
topics:
0. vectorization
1. broadcasting
2. einistien summation
3. kaiming initialization to keep mean zero and 1 std.
4. surpassing human level performance on imagenet (resnet paper)
5. the matrix calculus you need for deep learning (paper)

### lesson 9
topics:
0. why initing matrixes in deep model is important
1. fixup initialization paper.
2. what is cross entropy loss.
3. how to implement training loop.

### lesson 10
topics:
0. pytorch hooks.
1. batchnorm.
2. conv2d
3. model histogram
4. hooks

### lesson 11
topics:
0. all you need is a good init papaer.
1. imagenet and imagewoff
2. conv2d
3. data block api
4. optimizer
5. data augmentation on gpu
   
### lesson 12
1. mixup paper.
2. label smoothing
3. bag of trix paper.
4. transfer learning
5. discrimitive learning rate.
6. nlp
7. rnn