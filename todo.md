# Todo
## later:
#### catching up with recent changes in the field.
- [ ] learn about gpt-3.
- [ ] review RL book and read about actor-critic from it
- [ ] read more about data augmentation in RL.
- [ ] read more about offline RL.
- [ ] https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html
- [ ] https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html

## 1399-06-24 saturday (from 10:00 to 12:00)
- [x] watching this video [[32]]

## 1399-05-17 friday (from 10:00 to 12:30)
- [x] read spin up [introduction](https://spinningup.openai.com/en/latest/user/introduction.html)
- [x] [install spin up](https://spinningup.openai.com/en/latest/user/installation.html) on my computer
- [x] read algorithms section. this repo contains these algorithms, we should read through them and possibly optimize:
  * [ ] Vanilla Policy Gradient (VPG) 
  * [ ] Trust Region Policy Optimization (TRPO)
  * [ ] Proximal Policy Optimization (PPO)
  * [ ] Deep Deterministic Policy Gradient (DDPG)
  * [ ] Twin Delayed DDPG (TD3)
  * [ ] Soft Actor-Critic (SAC)
- [x] read [key concepts in RL](https://spinningup.openai.com/en/latest/spinningup/rl_intro.html) very good doc to introduce some one to rl terms and their meening.
- [x] read [Spinning Up as a Deep RL Researcher](https://spinningup.openai.com/en/latest/spinningup/spinningup.html) very good assay to show how to approach Deep RL. (I should read it again)
  * [ ] http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/
  * [ ] http://karpathy.github.io/2015/05/21/rnn-effectiveness/
  * [ ] http://colah.github.io/posts/2015-08-Understanding-LSTMs/
  * [ ] https://arxiv.org/abs/1312.6114
  * [ ] https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html
  * [ ] http://joschu.net/docs/thesis.pdf
  * [ ] https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf

## 1399-05-15 wednsday (from 9:30 to 11:30)
- [x] reading last remaining blog posts of https://www.alexirpan.com/ [[29]]

## 1399-05-07 tuesday (from 9:30 to 11:00)
- [x] reading three remaining blog posts of https://www.alexirpan.com/ [[24]]

## 1399-05-03 friday (from 10:00 to 12:30)
- [x] read about batch norm. [[25]]
- [x] read about hyper parameter tuning. [[26]]

## 1399-05-02 thursday (from 10:00 to 11:30)
- [x] continue read all recent blog posts of https://www.alexirpan.com/ [[24]]

## 1399-04-31 tuesday (from 9:00 to 11:30)
- [x] read https://himanshusahni.github.io/2018/02/23/reinforcement-learning-never-worked.html [[23]]
- [x] read all recent blog posts of https://www.alexirpan.com/ [[24]]

## 1399-04-30 monday (from 9:15 to 11:00)
- [x] read http://www.jtoy.net/blog/deep-reinforcement-learning-is-a-waste-of-time.html [[21]]
- [x] read https://www.alexirpan.com/2018/02/14/rl-hard.html [[22]]

## 1399-04-29 sunday (from 8:45 to 11:00)
- [x] Set up knowledge base
- [x] Learn how to use and setup some pages

[//begin]: # "Autogenerated link references for markdown compatibility"
[32]: rl-sitations\32 "32"
[29]: rl-sitations\29 "29"
[24]: rl-sitations\24 "All blog posts of "
[25]: rl-sitations\25 "25"
[26]: rl-sitations\26 "26"
[23]: rl-sitations\23 "Reinforcement Learning never worked, and 'deep' only helped a bit"
[21]: rl-sitations\21 "Deep Reinforcement Learning is a waste of time"
[22]: rl-sitations\22 "Deep Reinforcement Learning Doesn't Work Yet"
[//end]: # "Autogenerated link references"